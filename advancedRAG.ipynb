{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0dffb497-a0f0-4fd6-87a8-32db368c9e40",
   "metadata": {},
   "source": [
    "## Stting environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3de2bba-4666-464d-a07a-6d8eb3388e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "298bda23-01ff-4ea7-bf10-4c88cdf1e5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tavilt_token='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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e523dc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "HuggingFace_token='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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b61df01-bac3-4e2d-acc4-628c6227fc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "\n",
    "_set_env(\"TAVILY_API_KEY\")\n",
    "_set_env(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'true'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc9f55b",
   "metadata": {},
   "source": [
    "# Embeddings and Data store :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7db9ac15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n",
      "c:\\Users\\HADIL MARAI\\Desktop\\advancedrag\\Advanced_RAG\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "\n",
    "embeddings=HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "### from langchain_cohere import CohereEmbeddings\n",
    "\n",
    "\n",
    "\n",
    "# Docs to index\n",
    "urls = [\n",
    "    \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\",\n",
    "]\n",
    "\n",
    "# Load\n",
    "docs = [WebBaseLoader(url).load() for url in urls]\n",
    "docs_list = [item for sublist in docs for item in sublist]\n",
    "\n",
    "# Split\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=500, chunk_overlap=0\n",
    ")\n",
    "doc_splits = text_splitter.split_documents(docs_list)\n",
    "# Add to vectorDB\n",
    "vectorstore = FAISS.from_documents(\n",
    "    documents=doc_splits,\n",
    "    embedding=embeddings,\n",
    ")\n",
    "\n",
    "# Create retriever\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3eedb3e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/', 'title': \"Prompt Engineering | Lil'Log\", 'description': 'Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models.', 'language': 'en'}, page_content=\"Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.\\n[My personal spicy take] In my opinion, some prompt engineering papers are not worthy 8 pages long, since those tricks can be explained in one or a few sentences and the rest is all about benchmarking. An easy-to-use and shared benchmark infrastructure should be more beneficial to the community. Iterative prompting or external tool use would not be trivial to set up. Also non-trivial to align the whole research community to adopt it.\\nBasic Prompting#\\nZero-shot and few-shot learning are two most basic approaches for prompting the model, pioneered by many LLM papers and commonly used for benchmarking LLM performance.\\nZero-Shot#\\nZero-shot learning is to simply feed the task text to the model and ask for results.\\n(All the sentiment analysis examples are from SST-2)\\nText: i'll bet the video game is a lot more fun than the film.\\nSentiment:\\nFew-shot#\\nFew-shot learning presents a set of high-quality demonstrations, each consisting of both input and desired output, on the target task. As the model first sees good examples, it can better understand human intention and criteria for what kinds of answers are wanted. Therefore, few-shot learning often leads to better performance than zero-shot. However, it comes at the cost of more token consumption and may hit the context length limit when input and output text are long.\\nText: (lawrence bounces) all over the stage, dancing, running, sweating, mopping his face and generally displaying the wacky talent that brought him fame in the first place.\\nSentiment: positive\"),\n",
       " Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/', 'title': \"Prompt Engineering | Lil'Log\", 'description': 'Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models.', 'language': 'en'}, page_content='Or\\n@article{weng2023prompt,\\n  title   = \"Prompt Engineering\",\\n  author  = \"Weng, Lilian\",\\n  journal = \"lilianweng.github.io\",\\n  year    = \"2023\",\\n  month   = \"Mar\",\\n  url     = \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\"\\n}\\nUseful Resources#\\n\\nOpenAI Cookbook has many in-depth examples for how to utilize LLM efficiently.\\nLangChain, a library for combining language models with other components to build applications.\\nPrompt Engineering Guide repo contains a pretty comprehensive collection of education materials on prompt engineering.\\nlearnprompting.org\\nPromptPerfect\\nSemantic Kernel'),\n",
       " Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/', 'title': \"Prompt Engineering | Lil'Log\", 'description': 'Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models.', 'language': 'en'}, page_content=\"Prompt Engineering | Lil'Log\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nLil'Log\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nPosts\\n\\n\\n\\n\\nArchive\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\nTags\\n\\n\\n\\n\\nFAQ\\n\\n\\n\\n\\nemojisearch.app\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Prompt Engineering\\n    \\nDate: March 15, 2023  |  Estimated Reading Time: 21 min  |  Author: Lilian Weng\\n\\n\\n \\n\\n\\nTable of Contents\\n\\n\\n\\nBasic Prompting\\n\\nZero-Shot\\n\\nFew-shot\\n\\nTips for Example Selection\\n\\nTips for Example Ordering\\n\\n\\n\\nInstruction Prompting\\n\\nSelf-Consistency Sampling\\n\\nChain-of-Thought (CoT)\\n\\nTypes of CoT prompts\\n\\nTips and Extensions\\n\\n\\nAutomatic Prompt Design\\n\\nAugmented Language Models\\n\\nRetrieval\\n\\nProgramming Language\\n\\nExternal APIs\\n\\n\\nCitation\\n\\nUseful Resources\\n\\nReferences\"),\n",
       " Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/', 'title': \"Prompt Engineering | Lil'Log\", 'description': 'Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models.', 'language': 'en'}, page_content='... in language that is safe for work.\\nIn-context instruction learning (Ye et al. 2023) combines few-shot learning with instruction prompting. It incorporates multiple demonstration examples across different tasks in the prompt, each demonstration consisting of instruction, task input and output. Note that their experiments were only on classification tasks and the instruction prompt contains all label options.\\nDefinition: Determine the speaker of the dialogue, \"agent\" or \"customer\".\\nInput: I have successfully booked your tickets.\\nOuput: agent\\n\\nDefinition: Determine which category the question asks for, \"Quantity\" or \"Location\".\\nInput: What\\'s the oldest building in US?\\nOuput: Location\\n\\nDefinition: Classify the sentiment of the given movie review, \"positive\" or \"negative\".\\nInput: i\\'ll bet the video game is a lot more fun than the film.\\nOutput:\\nSelf-Consistency Sampling#\\nSelf-consistency sampling (Wang et al. 2022a) is to sample multiple outputs with temperature > 0 and then selecting the best one out of these candidates.\\nThe criteria for selecting the best candidate can vary from task to task. A general solution is to pick majority vote. For tasks that are easy to validate such as a programming question with unit tests, we can simply run through the interpreter and verify the correctness with unit tests.\\nChain-of-Thought (CoT)#\\nChain-of-thought (CoT) prompting (Wei et al. 2022) generates a sequence of short sentences to describe reasoning logics step by step, known as reasoning chains or rationales, to eventually lead to the final answer. The benefit of CoT is more pronounced for complicated reasoning tasks, while using large models (e.g. with more than 50B parameters). Simple tasks only benefit slightly from CoT prompting.\\nTypes of CoT prompts#\\nTwo main types of CoT prompting:\\n\\nFew-shot CoT. It is to prompt the model with a few demonstrations, each containing manually written (or model-generated) high-quality reasoning chains.')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke('prompt engineering')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d96cbb",
   "metadata": {},
   "source": [
    "# LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bba1c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "llm = ChatGroq(\n",
    "    model=\"llama-3.1-70b-versatile\",\n",
    "    temperature=0.2,\n",
    "    groq_api_key='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'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f19e0357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasource='websearch'\n",
      "datasource='vectorstore'\n"
     ]
    }
   ],
   "source": [
    "### Router\n",
    "\n",
    "from typing import Literal\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# Data model\n",
    "class RouteQuery(BaseModel):\n",
    "    \"\"\" Route a user query to the most relevant datasource. \"\"\"\n",
    "\n",
    "    datasource: Literal[\"vectorstore\", \"websearch\"] = Field(\n",
    "        ...,\n",
    "        description=\"Given a user question choose to route it to web search or a vectorstore.\",\n",
    "    )\n",
    "\n",
    "# LLM with structured output\n",
    "structured_llm_router = llm.with_structured_output(RouteQuery)\n",
    "\n",
    "# Prompt \n",
    "router_instructions = \"\"\"You are an expert at routing a user question to a vectorstore or web search.\n",
    "\n",
    "The vectorstore contains documents related to agents, prompt engineering, and adversarial attacks.\n",
    "                                    \n",
    "Use the vectorstore for questions on these topics. For all else, use web-search.\"\"\"\n",
    "\n",
    "# Test router\n",
    "print(structured_llm_router.invoke([SystemMessage(content=router_instructions)] + [HumanMessage(content=\"Who will the Bears draft first in the NFL draft?\")]))\n",
    "print(structured_llm_router.invoke([SystemMessage(content=router_instructions)] + [HumanMessage(content=\"What are the types of agent memory?\")]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc7ebb7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HADIL MARAI\\AppData\\Local\\Temp\\ipykernel_14148\\2753931103.py:26: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  docs = retriever.get_relevant_documents(question)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary_score='yes'\n"
     ]
    }
   ],
   "source": [
    "### Retrieval Grader \n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Data model\n",
    "class GradeDocuments(BaseModel):\n",
    "    \"\"\"Binary score for relevance check on retrieved documents.\"\"\"\n",
    "\n",
    "    binary_score: str = Field(description=\"Documents are relevant to the question, 'yes' or 'no'\")\n",
    "\n",
    "# LLM with structured output\n",
    "structured_llm_doc_grader = llm.with_structured_output(GradeDocuments)\n",
    "\n",
    "# Doc grader instructions \n",
    "doc_grader_instructions = \"\"\"You are a grader assessing relevance of a retrieved document to a user question.\n",
    "\n",
    "If the document contains keyword(s) or semantic meaning related to the question, grade it as relevant.\n",
    "\n",
    "Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\"\"\"\n",
    "\n",
    "# Grader prompt\n",
    "doc_grader_prompt = \"Here is the retrieved document: \\n\\n {document} \\n\\n Here is the user question: \\n\\n {question}\"\n",
    "\n",
    "# Test\n",
    "question = \"AI agent\"\n",
    "docs = retriever.get_relevant_documents(question)\n",
    "doc_txt = docs[1].page_content\n",
    "doc_grader_prompt_formatted = doc_grader_prompt.format(document=doc_txt, question=question)\n",
    "print(structured_llm_doc_grader.invoke([SystemMessage(content=doc_grader_instructions)] + [HumanMessage(content=doc_grader_prompt_formatted)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be701589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001E23AAF5280>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001E23A591700>, model_name='llama-3.1-70b-versatile', temperature=0.2, model_kwargs={}, groq_api_key=SecretStr('**********')), kwargs={'tools': [{'type': 'function', 'function': {'name': 'GradeDocuments', 'description': 'Binary score for relevance check on retrieved documents.', 'parameters': {'properties': {'binary_score': {'description': \"Documents are relevant to the question, 'yes' or 'no'\", 'type': 'string'}}, 'required': ['binary_score'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'GradeDocuments'}}}, config={}, config_factories=[])\n",
       "| PydanticToolsParser(first_tool_only=True, tools=[<class '__main__.GradeDocuments'>])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structured_llm_doc_grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0980ef75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The types of agent memory include: \n",
      "\n",
      "1. Sensory Memory: retains impressions of sensory information for a short period.\n",
      "2. Short-Term Memory (STM) or Working Memory: stores information for complex cognitive tasks, with a capacity of about 7 items and lasting 20-30 seconds.\n",
      "3. Long-Term Memory (LTM): stores information for a long time, with subtypes including explicit/declarative memory (facts and events) and implicit/procedural memory (skills and routines).\n"
     ]
    }
   ],
   "source": [
    "### Generate\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Prompt\n",
    "rag_prompt = \"\"\"You are an assistant for question-answering tasks. \n",
    "\n",
    "Use the following pieces of retrieved context to answer the question. \n",
    "\n",
    "If you don't know the answer, just say that you don't know. \n",
    "\n",
    "Use three sentences maximum and keep the answer concise.\n",
    "\n",
    "Question: {question} \n",
    "\n",
    "Context: {context} \n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "\n",
    "# Post-processing\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# Test\n",
    "question = \"The types of agent memory\"\n",
    "docs = retriever.get_relevant_documents(question)\n",
    "docs_txt = format_docs(docs)\n",
    "rag_prompt_formatted = rag_prompt.format(context=docs_txt, question=question)\n",
    "generation = llm.invoke([HumanMessage(content=rag_prompt_formatted)])\n",
    "print(generation.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "648ec026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes The student answer is grounded in the facts and does not contain any hallucinated information outside the scope of the facts. The student answer accurately lists the types of agent memory, including Sensory Memory, Short-Term Memory (STM) or Working Memory, and Long-Term Memory (LTM), along with their characteristics. The student answer is a direct reflection of the information provided in the facts, without any additional or made-up information.\n"
     ]
    }
   ],
   "source": [
    "### Hallucination Grader \n",
    "\n",
    "# Data model\n",
    "class GradeHallucinations(BaseModel):\n",
    "    \"\"\"Binary score for hallucination present in generation answer.\"\"\"\n",
    "\n",
    "    binary_score: str = Field(description=\"Answer is grounded in the facts, 'yes' or 'no'\")\n",
    "    explanation: str = Field(description=\"Explain the reasoning for the score\")\n",
    "\n",
    "# LLM with function call \n",
    "structured_llm_hallucination_grader = llm.with_structured_output(GradeHallucinations)\n",
    "\n",
    "# Hallucination grader instructions \n",
    "hallucination_grader_instructions = \"\"\"You are a teacher grading a quiz. \n",
    "\n",
    "You will be given FACTS and a STUDENT ANSWER. \n",
    "\n",
    "Here is the grade criteria to follow:\n",
    "\n",
    "(1) Ensure the STUDENT ANSWER is grounded in the FACTS. \n",
    "\n",
    "(2) Ensure the STUDENT ANSWER does not contain \"hallucinated\" information outside the scope of the FACTS.\n",
    "\n",
    "Score:\n",
    "\n",
    "A score of yes means that the student's answer meets all of the criteria. This is the highest (best) score. \n",
    "\n",
    "A score of no means that the student's answer does not meet all of the criteria. This is the lowest possible score you can give.\n",
    "\n",
    "Explain your reasoning in a step-by-step manner to ensure your reasoning and conclusion are correct. \n",
    "\n",
    "Avoid simply stating the correct answer at the outset.\"\"\"\n",
    "\n",
    "# Grader prompt\n",
    "hallucination_grader_prompt = \"FACTS: \\n\\n {documents} \\n\\n STUDENT ANSWER: {generation}\"\n",
    "\n",
    "# Test using documents and generation from above \n",
    "hallucination_grader_prompt_formatted = hallucination_grader_prompt.format(documents=docs_txt, generation=generation)\n",
    "score = structured_llm_hallucination_grader.invoke([SystemMessage(content=hallucination_grader_instructions)] + [HumanMessage(content=hallucination_grader_prompt_formatted)])\n",
    "print(score.binary_score, score.explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1c4e45e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradeHallucinations(binary_score='yes', explanation='The student answer is grounded in the facts and does not contain any hallucinated information outside the scope of the facts. The student answer accurately lists the types of agent memory, including Sensory Memory, Short-Term Memory (STM) or Working Memory, and Long-Term Memory (LTM), along with their characteristics. The student answer is a direct reflection of the information provided in the facts, without any additional or made-up information.')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "abf488b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes The student answer is concise and relevant to the question about the types of agent memory. The answer provides a clear and detailed list of the different types of agent memory, including sensory memory, short-term memory, and long-term memory, along with their characteristics. The answer helps to fully address the question and provides a comprehensive overview of the topic.\n"
     ]
    }
   ],
   "source": [
    "### Answer Grader \n",
    "\n",
    "# Data model\n",
    "class GradeAnswer(BaseModel):\n",
    "    \"\"\"Binary score to assess answer addresses question.\"\"\"\n",
    "\n",
    "    binary_score: str = Field(description=\"Answer addresses the question, 'yes' or 'no'\")\n",
    "    explanation: str = Field(description=\"Explain the reasoning for the score\")\n",
    "\n",
    "# LLM with function call \n",
    "structured_llm_answer_grader=llm.with_structured_output(GradeAnswer)\n",
    "\n",
    "# Answer grader instructions \n",
    "answer_grader_instructions = \"\"\"You are a teacher grading a quiz. \n",
    "\n",
    "You will be given a QUESTION and a STUDENT ANSWER. \n",
    "\n",
    "Here is the grade criteria to follow:\n",
    "\n",
    "(1) Ensure the STUDENT ANSWER is concise and relevant to the QUESTION\n",
    "\n",
    "(2) Ensure the STUDENT ANSWER helps to answer the QUESTION\n",
    "\n",
    "Score:\n",
    "\n",
    "A score of yes means that the student's answer meets all of the criteria. This is the highest (best) score. \n",
    "\n",
    "A score of no  means that the student's answer does not meet all of the criteria. This is the lowest possible score you can give.\n",
    "\n",
    "Explain your reasoning in a step-by-step manner to ensure your reasoning and conclusion are correct. \n",
    "\n",
    "Avoid simply stating the correct answer at the outset.\"\"\"\n",
    "\n",
    "# Grader prompt\n",
    "answer_grader_prompt = \"QUESTION: \\n\\n {question} \\n\\n STUDENT ANSWER: {generation}\"\n",
    "\n",
    "# Test using question and generation from above \n",
    "answer_grader_prompt_formatted = answer_grader_prompt.format(question=question, generation=generation)\n",
    "score = structured_llm_answer_grader.invoke([SystemMessage(content=answer_grader_instructions)] + [HumanMessage(content=answer_grader_prompt_formatted)])\n",
    "print(score.binary_score, score.explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "05ab9906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradeAnswer(binary_score='yes', explanation='The student answer is concise and relevant to the question about the types of agent memory. The answer provides a clear and detailed list of the different types of agent memory, including sensory memory, short-term memory, and long-term memory, along with their characteristics. The answer helps to fully address the question and provides a comprehensive overview of the topic.')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3200f2d8",
   "metadata": {},
   "source": [
    "## WebSearch tool :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e75c582",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "web_search_tool = TavilySearchResults(k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8356394",
   "metadata": {},
   "source": [
    "## Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d3b26239",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing_extensions import TypedDict\n",
    "from typing import List, Annotated\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Graph state is a dictionary that contains information we want to propagate to, and modify in, each graph node.\n",
    "    \"\"\"\n",
    "    question : str # User question\n",
    "    generation : str # LLM generation\n",
    "    web_search : str # Binary decision to run web search\n",
    "    max_retries : int # Max number of retries for answer generation \n",
    "    answers : int # Number of answers generated\n",
    "    loop_step: Annotated[int, operator.add] \n",
    "    documents : List[str] # List of retrieved documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "938f954c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "from langgraph.graph import END\n",
    "\n",
    "### Nodes\n",
    "def retrieve(state):\n",
    "    \"\"\"\n",
    "    Retrieve documents from vectorstore\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, documents, that contains retrieved documents\n",
    "    \"\"\"\n",
    "    print(\"---RETRIEVE---\")\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    # Write retrieved documents to documents key in state\n",
    "    documents = retriever.invoke(question)\n",
    "    return {\"documents\": documents}\n",
    "\n",
    "def generate(state):\n",
    "    \"\"\"\n",
    "    Generate answer using RAG on retrieved documents\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, generation, that contains LLM generation\n",
    "    \"\"\"\n",
    "    print(\"---GENERATE---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    loop_step = state.get(\"loop_step\", 0)\n",
    "    \n",
    "    # RAG generation\n",
    "    docs_txt = format_docs(documents)\n",
    "    rag_prompt_formatted = rag_prompt.format(context=docs_txt, question=question)\n",
    "    generation = llm.invoke([HumanMessage(content=rag_prompt_formatted)])\n",
    "    return {\"generation\": generation, \"loop_step\": loop_step+1}\n",
    "\n",
    "def grade_documents(state):\n",
    "    \"\"\"\n",
    "    Determines whether the retrieved documents are relevant to the question\n",
    "    If any document is not relevant, we will set a flag to run web search\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Filtered out irrelevant documents and updated web_search state\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---CHECK DOCUMENT RELEVANCE TO QUESTION---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    \n",
    "    # Score each doc\n",
    "    filtered_docs = []\n",
    "    web_search = \"No\" \n",
    "    for d in documents:\n",
    "        doc_grader_prompt_formatted = doc_grader_prompt.format(document=d.page_content, question=question)\n",
    "        score = structured_llm_doc_grader.invoke([SystemMessage(content=doc_grader_instructions)] + [HumanMessage(content=doc_grader_prompt_formatted)])\n",
    "        grade = score.binary_score\n",
    "        # Document relevant\n",
    "        if grade.lower() == \"yes\":\n",
    "            print(\"---GRADE: DOCUMENT RELEVANT---\")\n",
    "            filtered_docs.append(d)\n",
    "        # Document not relevant\n",
    "        else:\n",
    "            print(\"---GRADE: DOCUMENT NOT RELEVANT---\")\n",
    "            # We do not include the document in filtered_docs\n",
    "            # We set a flag to indicate that we want to run web search\n",
    "            web_search = \"Yes\"\n",
    "            continue\n",
    "    return {\"documents\": filtered_docs, \"web_search\": web_search}\n",
    "    \n",
    "def web_search(state):\n",
    "    \"\"\"\n",
    "    Web search based based on the question\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Appended web results to documents\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---WEB SEARCH---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state.get(\"documents\", [])\n",
    "\n",
    "    # Web search\n",
    "    docs = web_search_tool.invoke({\"query\": question})\n",
    "    web_results = \"\\n\".join([d[\"content\"] for d in docs])\n",
    "    web_results = Document(page_content=web_results)\n",
    "    documents.append(web_results)\n",
    "    return {\"documents\": documents}\n",
    "\n",
    "### Edges\n",
    "\n",
    "def route_question(state):\n",
    "    \"\"\"\n",
    "    Route question to web search or RAG \n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Next node to call\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---ROUTE QUESTION---\")\n",
    "    source = structured_llm_router.invoke([SystemMessage(content=router_instructions)] + [HumanMessage(content=state[\"question\"])]) \n",
    "    if source.datasource == 'websearch':\n",
    "        print(\"---ROUTE QUESTION TO WEB SEARCH---\")\n",
    "        return \"websearch\"\n",
    "    elif source.datasource == 'vectorstore':\n",
    "        print(\"---ROUTE QUESTION TO RAG---\")\n",
    "        return \"vectorstore\"\n",
    "\n",
    "def decide_to_generate(state):\n",
    "    \"\"\"\n",
    "    Determines whether to generate an answer, or add web search\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Binary decision for next node to call\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---ASSESS GRADED DOCUMENTS---\")\n",
    "    question = state[\"question\"]\n",
    "    web_search = state[\"web_search\"]\n",
    "    filtered_documents = state[\"documents\"]\n",
    "\n",
    "    if web_search == \"Yes\":\n",
    "        # All documents have been filtered check_relevance\n",
    "        # We will re-generate a new query\n",
    "        print(\"---DECISION: NOT ALL DOCUMENTS ARE RELEVANT TO QUESTION, INCLUDE WEB SEARCH---\")\n",
    "        return \"websearch\"\n",
    "    else:\n",
    "        # We have relevant documents, so generate answer\n",
    "        print(\"---DECISION: GENERATE---\")\n",
    "        return \"generate\"\n",
    "\n",
    "def grade_generation_v_documents_and_question(state):\n",
    "    \"\"\"\n",
    "    Determines whether the generation is grounded in the document and answers question\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Decision for next node to call\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---CHECK HALLUCINATIONS---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    generation = state[\"generation\"]\n",
    "    max_retries = state.get(\"max_retries\", 3) # Default to 3 if not provided\n",
    "\n",
    "    hallucination_grader_prompt_formatted = hallucination_grader_prompt.format(documents=format_docs(documents), generation=generation.content)\n",
    "    score = structured_llm_hallucination_grader.invoke([SystemMessage(content=hallucination_grader_instructions)] + [HumanMessage(content=hallucination_grader_prompt_formatted)])\n",
    "    grade = score.binary_score\n",
    "\n",
    "    # Check hallucination\n",
    "    if grade == \"yes\":\n",
    "        print(\"---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\")\n",
    "        # Check question-answering\n",
    "        print(\"---GRADE GENERATION vs QUESTION---\")\n",
    "        # Test using question and generation from above \n",
    "        answer_grader_prompt_formatted = answer_grader_prompt.format(question=question, generation=generation.content)\n",
    "        score = structured_llm_answer_grader.invoke([SystemMessage(content=answer_grader_instructions)] + [HumanMessage(content=answer_grader_prompt_formatted)])\n",
    "        grade = score.binary_score\n",
    "        if grade == \"yes\":\n",
    "            print(\"---DECISION: GENERATION ADDRESSES QUESTION---\")\n",
    "            return \"useful\"\n",
    "        elif state[\"loop_step\"] <= max_retries:\n",
    "            print(\"---DECISION: GENERATION DOES NOT ADDRESS QUESTION---\")\n",
    "            return \"not useful\"\n",
    "        else:\n",
    "            print(\"---DECISION: MAX RETRIES REACHED---\")\n",
    "            return \"max retries\"  \n",
    "    elif state[\"loop_step\"] <= max_retries:\n",
    "        print(\"---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---\")\n",
    "        return \"not supported\"\n",
    "    else:\n",
    "        print(\"---DECISION: MAX RETRIES REACHED---\")\n",
    "        return \"max retries\"  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a845c4",
   "metadata": {},
   "source": [
    "## Build Graph :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "abde6ec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph\n",
    "from IPython.display import Image, display\n",
    "\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# Define the nodes\n",
    "workflow.add_node(\"websearch\", web_search) # web search\n",
    "workflow.add_node(\"retrieve\", retrieve) # retrieve\n",
    "workflow.add_node(\"grade_documents\", grade_documents) # grade documents\n",
    "workflow.add_node(\"generate\", generate) # generatae\n",
    "\n",
    "# Build graph\n",
    "workflow.set_conditional_entry_point(\n",
    "    route_question,\n",
    "    {\n",
    "        \"websearch\": \"websearch\",\n",
    "        \"vectorstore\": \"retrieve\",\n",
    "    },\n",
    ")\n",
    "workflow.add_edge(\"websearch\", \"generate\")\n",
    "workflow.add_edge(\"retrieve\", \"grade_documents\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"grade_documents\",\n",
    "    decide_to_generate,\n",
    "    {\n",
    "        \"websearch\": \"websearch\",\n",
    "        \"generate\": \"generate\",\n",
    "    },\n",
    ")\n",
    "workflow.add_conditional_edges(\n",
    "    \"generate\",\n",
    "    grade_generation_v_documents_and_question,\n",
    "    {\n",
    "        \"not supported\": \"generate\",\n",
    "        \"useful\": END,\n",
    "        \"not useful\": \"websearch\",\n",
    "        \"max retries\": END,\n",
    "    },\n",
    ")\n",
    "\n",
    "# Compile\n",
    "graph = workflow.compile()\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "77da1d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---ROUTE QUESTION---\n",
      "---ROUTE QUESTION TO RAG---\n",
      "{'question': 'What are the types of agent memory?', 'max_retries': 3, 'loop_step': 0}\n",
      "---RETRIEVE---\n",
      "{'question': 'What are the types of agent memory?', 'max_retries': 3, 'loop_step': 0, 'documents': [Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en'}, page_content='Fig. 7. Comparison of AD, ED, source policy and RL^2 on environments that require memory and exploration. Only binary reward is assigned. The source policies are trained with A3C for \"dark\" environments and DQN for watermaze.(Image source: Laskin et al. 2023)\\nComponent Two: Memory#\\n(Big thank you to ChatGPT for helping me draft this section. I’ve learned a lot about the human brain and data structure for fast MIPS in my conversations with ChatGPT.)\\nTypes of Memory#\\nMemory can be defined as the processes used to acquire, store, retain, and later retrieve information. There are several types of memory in human brains.\\n\\n\\nSensory Memory: This is the earliest stage of memory, providing the ability to retain impressions of sensory information (visual, auditory, etc) after the original stimuli have ended. Sensory memory typically only lasts for up to a few seconds. Subcategories include iconic memory (visual), echoic memory (auditory), and haptic memory (touch).\\n\\n\\nShort-Term Memory (STM) or Working Memory: It stores information that we are currently aware of and needed to carry out complex cognitive tasks such as learning and reasoning. Short-term memory is believed to have the capacity of about 7 items (Miller 1956) and lasts for 20-30 seconds.\\n\\n\\nLong-Term Memory (LTM): Long-term memory can store information for a remarkably long time, ranging from a few days to decades, with an essentially unlimited storage capacity. There are two subtypes of LTM:\\n\\nExplicit / declarative memory: This is memory of facts and events, and refers to those memories that can be consciously recalled, including episodic memory (events and experiences) and semantic memory (facts and concepts).\\nImplicit / procedural memory: This type of memory is unconscious and involves skills and routines that are performed automatically, like riding a bike or typing on a keyboard.\\n\\n\\n\\n\\nFig. 8. Categorization of human memory.\\nWe can roughly consider the following mappings:'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en'}, page_content='inquired about current trends in anticancer drug discovery;\\nselected a target;\\nrequested a scaffold targeting these compounds;\\nOnce the compound was identified, the model attempted its synthesis.\\n\\nThey also discussed the risks, especially with illicit drugs and bioweapons. They developed a test set containing a list of known chemical weapon agents and asked the agent to synthesize them. 4 out of 11 requests (36%) were accepted to obtain a synthesis solution and the agent attempted to consult documentation to execute the procedure. 7 out of 11 were rejected and among these 7 rejected cases, 5 happened after a Web search while 2 were rejected based on prompt only.\\nGenerative Agents Simulation#\\nGenerative Agents (Park, et al. 2023) is super fun experiment where 25 virtual characters, each controlled by a LLM-powered agent, are living and interacting in a sandbox environment, inspired by The Sims. Generative agents create believable simulacra of human behavior for interactive applications.\\nThe design of generative agents combines LLM with memory, planning and reflection mechanisms to enable agents to behave conditioned on past experience, as well as to interact with other agents.\\n\\nMemory stream: is a long-term memory module (external database) that records a comprehensive list of agents’ experience in natural language.\\n\\nEach element is an observation, an event directly provided by the agent.\\n- Inter-agent communication can trigger new natural language statements.\\n\\n\\nRetrieval model: surfaces the context to inform the agent’s behavior, according to relevance, recency and importance.\\n\\nRecency: recent events have higher scores\\nImportance: distinguish mundane from core memories. Ask LM directly.\\nRelevance: based on how related it is to the current situation / query.\\n\\n\\nReflection mechanism: synthesizes memories into higher level inferences over time and guides the agent’s future behavior. They are higher-level summaries of past events (<- note that this is a bit different from self-reflection above)\\n\\nPrompt LM with 100 most recent observations and to generate 3 most salient high-level questions given a set of observations/statements. Then ask LM to answer those questions.\\n\\n\\nPlanning & Reacting: translate the reflections and the environment information into actions'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en'}, page_content=\"LLM Powered Autonomous Agents | Lil'Log\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nLil'Log\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nPosts\\n\\n\\n\\n\\nArchive\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\nTags\\n\\n\\n\\n\\nFAQ\\n\\n\\n\\n\\nemojisearch.app\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\\n\\n\\n \\n\\n\\nTable of Contents\\n\\n\\n\\nAgent System Overview\\n\\nComponent One: Planning\\n\\nTask Decomposition\\n\\nSelf-Reflection\\n\\n\\nComponent Two: Memory\\n\\nTypes of Memory\\n\\nMaximum Inner Product Search (MIPS)\\n\\n\\nComponent Three: Tool Use\\n\\nCase Studies\\n\\nScientific Discovery Agent\\n\\nGenerative Agents Simulation\\n\\nProof-of-Concept Examples\\n\\n\\nChallenges\\n\\nCitation\\n\\nReferences\\n\\n\\n\\n\\n\\nBuilding agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\"), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en'}, page_content='Planning is essentially in order to optimize believability at the moment vs in time.\\nPrompt template: {Intro of an agent X}. Here is X\\'s plan today in broad strokes: 1)\\nRelationships between agents and observations of one agent by another are all taken into consideration for planning and reacting.\\nEnvironment information is present in a tree structure.\\n\\n\\n\\n\\nFig. 13. The generative agent architecture. (Image source: Park et al. 2023)\\nThis fun simulation results in emergent social behavior, such as information diffusion, relationship memory (e.g. two agents continuing the conversation topic) and coordination of social events (e.g. host a party and invite many others).\\nProof-of-Concept Examples#\\nAutoGPT has drawn a lot of attention into the possibility of setting up autonomous agents with LLM as the main controller. It has quite a lot of reliability issues given the natural language interface, but nevertheless a cool proof-of-concept demo. A lot of code in AutoGPT is about format parsing.\\nHere is the system message used by AutoGPT, where {{...}} are user inputs:\\nYou are {{ai-name}}, {{user-provided AI bot description}}.\\nYour decisions must always be made independently without seeking user assistance. Play to your strengths as an LLM and pursue simple strategies with no legal complications.\\n\\nGOALS:\\n\\n1. {{user-provided goal 1}}\\n2. {{user-provided goal 2}}\\n3. ...\\n4. ...\\n5. ...\\n\\nConstraints:\\n1. ~4000 word limit for short term memory. Your short term memory is short, so immediately save important information to files.\\n2. If you are unsure how you previously did something or want to recall past events, thinking about similar events will help you remember.\\n3. No user assistance\\n4. Exclusively use the commands listed in double quotes e.g. \"command name\"\\n5. Use subprocesses for commands that will not terminate within a few minutes')]}\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "---DECISION: NOT ALL DOCUMENTS ARE RELEVANT TO QUESTION, INCLUDE WEB SEARCH---\n",
      "{'question': 'What are the types of agent memory?', 'web_search': 'Yes', 'max_retries': 3, 'loop_step': 0, 'documents': [Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en'}, page_content='inquired about current trends in anticancer drug discovery;\\nselected a target;\\nrequested a scaffold targeting these compounds;\\nOnce the compound was identified, the model attempted its synthesis.\\n\\nThey also discussed the risks, especially with illicit drugs and bioweapons. They developed a test set containing a list of known chemical weapon agents and asked the agent to synthesize them. 4 out of 11 requests (36%) were accepted to obtain a synthesis solution and the agent attempted to consult documentation to execute the procedure. 7 out of 11 were rejected and among these 7 rejected cases, 5 happened after a Web search while 2 were rejected based on prompt only.\\nGenerative Agents Simulation#\\nGenerative Agents (Park, et al. 2023) is super fun experiment where 25 virtual characters, each controlled by a LLM-powered agent, are living and interacting in a sandbox environment, inspired by The Sims. Generative agents create believable simulacra of human behavior for interactive applications.\\nThe design of generative agents combines LLM with memory, planning and reflection mechanisms to enable agents to behave conditioned on past experience, as well as to interact with other agents.\\n\\nMemory stream: is a long-term memory module (external database) that records a comprehensive list of agents’ experience in natural language.\\n\\nEach element is an observation, an event directly provided by the agent.\\n- Inter-agent communication can trigger new natural language statements.\\n\\n\\nRetrieval model: surfaces the context to inform the agent’s behavior, according to relevance, recency and importance.\\n\\nRecency: recent events have higher scores\\nImportance: distinguish mundane from core memories. Ask LM directly.\\nRelevance: based on how related it is to the current situation / query.\\n\\n\\nReflection mechanism: synthesizes memories into higher level inferences over time and guides the agent’s future behavior. They are higher-level summaries of past events (<- note that this is a bit different from self-reflection above)\\n\\nPrompt LM with 100 most recent observations and to generate 3 most salient high-level questions given a set of observations/statements. Then ask LM to answer those questions.\\n\\n\\nPlanning & Reacting: translate the reflections and the environment information into actions'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en'}, page_content=\"LLM Powered Autonomous Agents | Lil'Log\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nLil'Log\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nPosts\\n\\n\\n\\n\\nArchive\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\nTags\\n\\n\\n\\n\\nFAQ\\n\\n\\n\\n\\nemojisearch.app\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\\n\\n\\n \\n\\n\\nTable of Contents\\n\\n\\n\\nAgent System Overview\\n\\nComponent One: Planning\\n\\nTask Decomposition\\n\\nSelf-Reflection\\n\\n\\nComponent Two: Memory\\n\\nTypes of Memory\\n\\nMaximum Inner Product Search (MIPS)\\n\\n\\nComponent Three: Tool Use\\n\\nCase Studies\\n\\nScientific Discovery Agent\\n\\nGenerative Agents Simulation\\n\\nProof-of-Concept Examples\\n\\n\\nChallenges\\n\\nCitation\\n\\nReferences\\n\\n\\n\\n\\n\\nBuilding agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\"), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en'}, page_content='Planning is essentially in order to optimize believability at the moment vs in time.\\nPrompt template: {Intro of an agent X}. Here is X\\'s plan today in broad strokes: 1)\\nRelationships between agents and observations of one agent by another are all taken into consideration for planning and reacting.\\nEnvironment information is present in a tree structure.\\n\\n\\n\\n\\nFig. 13. The generative agent architecture. (Image source: Park et al. 2023)\\nThis fun simulation results in emergent social behavior, such as information diffusion, relationship memory (e.g. two agents continuing the conversation topic) and coordination of social events (e.g. host a party and invite many others).\\nProof-of-Concept Examples#\\nAutoGPT has drawn a lot of attention into the possibility of setting up autonomous agents with LLM as the main controller. It has quite a lot of reliability issues given the natural language interface, but nevertheless a cool proof-of-concept demo. A lot of code in AutoGPT is about format parsing.\\nHere is the system message used by AutoGPT, where {{...}} are user inputs:\\nYou are {{ai-name}}, {{user-provided AI bot description}}.\\nYour decisions must always be made independently without seeking user assistance. Play to your strengths as an LLM and pursue simple strategies with no legal complications.\\n\\nGOALS:\\n\\n1. {{user-provided goal 1}}\\n2. {{user-provided goal 2}}\\n3. ...\\n4. ...\\n5. ...\\n\\nConstraints:\\n1. ~4000 word limit for short term memory. Your short term memory is short, so immediately save important information to files.\\n2. If you are unsure how you previously did something or want to recall past events, thinking about similar events will help you remember.\\n3. No user assistance\\n4. Exclusively use the commands listed in double quotes e.g. \"command name\"\\n5. Use subprocesses for commands that will not terminate within a few minutes')]}\n",
      "---WEB SEARCH---\n",
      "{'question': 'What are the types of agent memory?', 'web_search': 'Yes', 'max_retries': 3, 'loop_step': 0, 'documents': [Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en'}, page_content='inquired about current trends in anticancer drug discovery;\\nselected a target;\\nrequested a scaffold targeting these compounds;\\nOnce the compound was identified, the model attempted its synthesis.\\n\\nThey also discussed the risks, especially with illicit drugs and bioweapons. They developed a test set containing a list of known chemical weapon agents and asked the agent to synthesize them. 4 out of 11 requests (36%) were accepted to obtain a synthesis solution and the agent attempted to consult documentation to execute the procedure. 7 out of 11 were rejected and among these 7 rejected cases, 5 happened after a Web search while 2 were rejected based on prompt only.\\nGenerative Agents Simulation#\\nGenerative Agents (Park, et al. 2023) is super fun experiment where 25 virtual characters, each controlled by a LLM-powered agent, are living and interacting in a sandbox environment, inspired by The Sims. Generative agents create believable simulacra of human behavior for interactive applications.\\nThe design of generative agents combines LLM with memory, planning and reflection mechanisms to enable agents to behave conditioned on past experience, as well as to interact with other agents.\\n\\nMemory stream: is a long-term memory module (external database) that records a comprehensive list of agents’ experience in natural language.\\n\\nEach element is an observation, an event directly provided by the agent.\\n- Inter-agent communication can trigger new natural language statements.\\n\\n\\nRetrieval model: surfaces the context to inform the agent’s behavior, according to relevance, recency and importance.\\n\\nRecency: recent events have higher scores\\nImportance: distinguish mundane from core memories. Ask LM directly.\\nRelevance: based on how related it is to the current situation / query.\\n\\n\\nReflection mechanism: synthesizes memories into higher level inferences over time and guides the agent’s future behavior. They are higher-level summaries of past events (<- note that this is a bit different from self-reflection above)\\n\\nPrompt LM with 100 most recent observations and to generate 3 most salient high-level questions given a set of observations/statements. Then ask LM to answer those questions.\\n\\n\\nPlanning & Reacting: translate the reflections and the environment information into actions'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en'}, page_content=\"LLM Powered Autonomous Agents | Lil'Log\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nLil'Log\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nPosts\\n\\n\\n\\n\\nArchive\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\nTags\\n\\n\\n\\n\\nFAQ\\n\\n\\n\\n\\nemojisearch.app\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\\n\\n\\n \\n\\n\\nTable of Contents\\n\\n\\n\\nAgent System Overview\\n\\nComponent One: Planning\\n\\nTask Decomposition\\n\\nSelf-Reflection\\n\\n\\nComponent Two: Memory\\n\\nTypes of Memory\\n\\nMaximum Inner Product Search (MIPS)\\n\\n\\nComponent Three: Tool Use\\n\\nCase Studies\\n\\nScientific Discovery Agent\\n\\nGenerative Agents Simulation\\n\\nProof-of-Concept Examples\\n\\n\\nChallenges\\n\\nCitation\\n\\nReferences\\n\\n\\n\\n\\n\\nBuilding agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\"), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en'}, page_content='Planning is essentially in order to optimize believability at the moment vs in time.\\nPrompt template: {Intro of an agent X}. Here is X\\'s plan today in broad strokes: 1)\\nRelationships between agents and observations of one agent by another are all taken into consideration for planning and reacting.\\nEnvironment information is present in a tree structure.\\n\\n\\n\\n\\nFig. 13. The generative agent architecture. (Image source: Park et al. 2023)\\nThis fun simulation results in emergent social behavior, such as information diffusion, relationship memory (e.g. two agents continuing the conversation topic) and coordination of social events (e.g. host a party and invite many others).\\nProof-of-Concept Examples#\\nAutoGPT has drawn a lot of attention into the possibility of setting up autonomous agents with LLM as the main controller. It has quite a lot of reliability issues given the natural language interface, but nevertheless a cool proof-of-concept demo. A lot of code in AutoGPT is about format parsing.\\nHere is the system message used by AutoGPT, where {{...}} are user inputs:\\nYou are {{ai-name}}, {{user-provided AI bot description}}.\\nYour decisions must always be made independently without seeking user assistance. Play to your strengths as an LLM and pursue simple strategies with no legal complications.\\n\\nGOALS:\\n\\n1. {{user-provided goal 1}}\\n2. {{user-provided goal 2}}\\n3. ...\\n4. ...\\n5. ...\\n\\nConstraints:\\n1. ~4000 word limit for short term memory. Your short term memory is short, so immediately save important information to files.\\n2. If you are unsure how you previously did something or want to recall past events, thinking about similar events will help you remember.\\n3. No user assistance\\n4. Exclusively use the commands listed in double quotes e.g. \"command name\"\\n5. Use subprocesses for commands that will not terminate within a few minutes'), Document(metadata={}, page_content='Deep dive into various types of Agent Memory STM: Working memory (LLM Context): It is a data structure with multiple parts which are usually represented with a prompt template and relevant variables.Before runtime, the STM is synthesized by replacing the relevant variables in the prompt template with information retrieved from the LTM.\\nMemory for agents Memory for agents At Sequoia’s AI Ascent conference in March, I talked about three limitations for agents: planning, UX, and memory. But what even is memory? While the exact shape of memory that your agent has may differ by application, we do see different high level types of memory. Below is my rough, ELI5 explanation of each type and practical ways for how todays agents may use and update this memory type. Besides just thinking about the type of memory to update in their agents, we also see developers thinking about how to update agent memory. One way to update agent memory is “in the hot path”. Why do we care about memory for agents?\\nMemory Management In AI Agents Memory Management In AI Agents Explore memory management techniques in AI agents, focusing on efficiency and optimization for enhanced performance. Types of Memory in AI Agents Types of Memory in AI Agents ---------------------------- Memory management in AI agents incorporates short-term memory for context and long-term memory using external storage, such as vector databases, enabling efficient information retrieval and enhanced reasoning. Memory management in AI agents is crucial for optimizing performance and enhancing user interactions. By leveraging short-term, long-term, and contextual memory, agents can provide more personalized and efficient interactions, ultimately leading to better outcomes for users. This ongoing development aims to enhance memory management in AI agents, ensuring they can provide more coherent and contextually relevant interactions. Types of Memory in AI Agents\\nSign up for Latest SuperAGI Updates\\n\"*\" indicates required fields\\nSuperAGI builds infrastructure components, tools, frameworks and models to enable opensource AGI\\ncommunity@superagi.com\\nFor Developers\\nDocs\\nGitHub\\nReleases\\nRoadmap\\nAPIs\\nCommunity\\nSupport Forum\\nMarketplace\\nSocial Mentions\\nReddit\\nCollectibles\\nResources\\nBlog\\nUse Cases\\nAGI Research Lab\\nTutorials\\nImportant Links\\nSuperAGI Cloud\\nApp Spotlight\\nSuperCoder\\nArchitecture\\n Check it out✨\\nFeatures\\nAction Console\\nResource Manager\\nTrajectory Fine-Tuning\\n\\u200c\\nMultiple Vector DBs\\nMulti-LLM Support\\nAgent Workflows\\nMarketplace\\nAgent Templates\\nDiscord\\nGitHub\\nTwitter\\nReddit\\nYoutube\\nTowards AGI (part 1): Agents with Memory\\nFebruary 6, 2024\\n7 mins read\\nAgents are an emerging class of artificial intelligence (AI) systems that use large language models (LLMs) to interact with the world. In a professional setup like this, the agent is responsible for extracting tasks from conversations and passing them to an employee and once the employee completes the task the agent will convey the output to the user. Then use the solutions of those basic tasks as in-context examples to solve the current task.\\nConclusion & Next Steps\\nIn this blog, we saw that design choices for Memory depend on the end use case. This analogy is better captured in the following table:\\nDeep dive into various types of Agent Memory\\nChoosing the right Memory design in Production\\nSince agents are powered by LLMs, they are inherently probabilistic.\\nMemory: an AI agent combines the ability to use short-term memory to process chat-based prompts and follow-up prompts with longer-term data retention and recall (often via retrieval augmented generation, or RAG). Tool use: an agent can query APIs to request additional information or execute an action based on an end user\\'s request.')]}\n",
      "---GENERATE---\n",
      "---CHECK HALLUCINATIONS---\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION vs QUESTION---\n",
      "---DECISION: GENERATION ADDRESSES QUESTION---\n",
      "{'question': 'What are the types of agent memory?', 'generation': AIMessage(content='The types of agent memory include: \\n\\n1. Short-term memory (STM): Working memory (LLM Context) that is a data structure with multiple parts, usually represented with a prompt template and relevant variables.\\n2. Long-term memory (LTM): Provides the agent with the capability to retain and recall information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\nAdditionally, contextual memory is also mentioned as a type of memory in AI agents, enabling efficient information retrieval and enhanced reasoning.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 102, 'prompt_tokens': 2065, 'total_tokens': 2167, 'completion_time': 0.408, 'prompt_time': 0.373743337, 'queue_time': 0.004000214999999974, 'total_time': 0.781743337}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_9260b4bb2e', 'finish_reason': 'stop', 'logprobs': None}, id='run-2b0b6166-2baa-44dc-9b40-6e3eea5b78e4-0', usage_metadata={'input_tokens': 2065, 'output_tokens': 102, 'total_tokens': 2167}), 'web_search': 'Yes', 'max_retries': 3, 'loop_step': 1, 'documents': [Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en'}, page_content='inquired about current trends in anticancer drug discovery;\\nselected a target;\\nrequested a scaffold targeting these compounds;\\nOnce the compound was identified, the model attempted its synthesis.\\n\\nThey also discussed the risks, especially with illicit drugs and bioweapons. They developed a test set containing a list of known chemical weapon agents and asked the agent to synthesize them. 4 out of 11 requests (36%) were accepted to obtain a synthesis solution and the agent attempted to consult documentation to execute the procedure. 7 out of 11 were rejected and among these 7 rejected cases, 5 happened after a Web search while 2 were rejected based on prompt only.\\nGenerative Agents Simulation#\\nGenerative Agents (Park, et al. 2023) is super fun experiment where 25 virtual characters, each controlled by a LLM-powered agent, are living and interacting in a sandbox environment, inspired by The Sims. Generative agents create believable simulacra of human behavior for interactive applications.\\nThe design of generative agents combines LLM with memory, planning and reflection mechanisms to enable agents to behave conditioned on past experience, as well as to interact with other agents.\\n\\nMemory stream: is a long-term memory module (external database) that records a comprehensive list of agents’ experience in natural language.\\n\\nEach element is an observation, an event directly provided by the agent.\\n- Inter-agent communication can trigger new natural language statements.\\n\\n\\nRetrieval model: surfaces the context to inform the agent’s behavior, according to relevance, recency and importance.\\n\\nRecency: recent events have higher scores\\nImportance: distinguish mundane from core memories. Ask LM directly.\\nRelevance: based on how related it is to the current situation / query.\\n\\n\\nReflection mechanism: synthesizes memories into higher level inferences over time and guides the agent’s future behavior. They are higher-level summaries of past events (<- note that this is a bit different from self-reflection above)\\n\\nPrompt LM with 100 most recent observations and to generate 3 most salient high-level questions given a set of observations/statements. Then ask LM to answer those questions.\\n\\n\\nPlanning & Reacting: translate the reflections and the environment information into actions'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en'}, page_content=\"LLM Powered Autonomous Agents | Lil'Log\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nLil'Log\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nPosts\\n\\n\\n\\n\\nArchive\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\nTags\\n\\n\\n\\n\\nFAQ\\n\\n\\n\\n\\nemojisearch.app\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\\n\\n\\n \\n\\n\\nTable of Contents\\n\\n\\n\\nAgent System Overview\\n\\nComponent One: Planning\\n\\nTask Decomposition\\n\\nSelf-Reflection\\n\\n\\nComponent Two: Memory\\n\\nTypes of Memory\\n\\nMaximum Inner Product Search (MIPS)\\n\\n\\nComponent Three: Tool Use\\n\\nCase Studies\\n\\nScientific Discovery Agent\\n\\nGenerative Agents Simulation\\n\\nProof-of-Concept Examples\\n\\n\\nChallenges\\n\\nCitation\\n\\nReferences\\n\\n\\n\\n\\n\\nBuilding agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\"), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en'}, page_content='Planning is essentially in order to optimize believability at the moment vs in time.\\nPrompt template: {Intro of an agent X}. Here is X\\'s plan today in broad strokes: 1)\\nRelationships between agents and observations of one agent by another are all taken into consideration for planning and reacting.\\nEnvironment information is present in a tree structure.\\n\\n\\n\\n\\nFig. 13. The generative agent architecture. (Image source: Park et al. 2023)\\nThis fun simulation results in emergent social behavior, such as information diffusion, relationship memory (e.g. two agents continuing the conversation topic) and coordination of social events (e.g. host a party and invite many others).\\nProof-of-Concept Examples#\\nAutoGPT has drawn a lot of attention into the possibility of setting up autonomous agents with LLM as the main controller. It has quite a lot of reliability issues given the natural language interface, but nevertheless a cool proof-of-concept demo. A lot of code in AutoGPT is about format parsing.\\nHere is the system message used by AutoGPT, where {{...}} are user inputs:\\nYou are {{ai-name}}, {{user-provided AI bot description}}.\\nYour decisions must always be made independently without seeking user assistance. Play to your strengths as an LLM and pursue simple strategies with no legal complications.\\n\\nGOALS:\\n\\n1. {{user-provided goal 1}}\\n2. {{user-provided goal 2}}\\n3. ...\\n4. ...\\n5. ...\\n\\nConstraints:\\n1. ~4000 word limit for short term memory. Your short term memory is short, so immediately save important information to files.\\n2. If you are unsure how you previously did something or want to recall past events, thinking about similar events will help you remember.\\n3. No user assistance\\n4. Exclusively use the commands listed in double quotes e.g. \"command name\"\\n5. Use subprocesses for commands that will not terminate within a few minutes'), Document(metadata={}, page_content='Deep dive into various types of Agent Memory STM: Working memory (LLM Context): It is a data structure with multiple parts which are usually represented with a prompt template and relevant variables.Before runtime, the STM is synthesized by replacing the relevant variables in the prompt template with information retrieved from the LTM.\\nMemory for agents Memory for agents At Sequoia’s AI Ascent conference in March, I talked about three limitations for agents: planning, UX, and memory. But what even is memory? While the exact shape of memory that your agent has may differ by application, we do see different high level types of memory. Below is my rough, ELI5 explanation of each type and practical ways for how todays agents may use and update this memory type. Besides just thinking about the type of memory to update in their agents, we also see developers thinking about how to update agent memory. One way to update agent memory is “in the hot path”. Why do we care about memory for agents?\\nMemory Management In AI Agents Memory Management In AI Agents Explore memory management techniques in AI agents, focusing on efficiency and optimization for enhanced performance. Types of Memory in AI Agents Types of Memory in AI Agents ---------------------------- Memory management in AI agents incorporates short-term memory for context and long-term memory using external storage, such as vector databases, enabling efficient information retrieval and enhanced reasoning. Memory management in AI agents is crucial for optimizing performance and enhancing user interactions. By leveraging short-term, long-term, and contextual memory, agents can provide more personalized and efficient interactions, ultimately leading to better outcomes for users. This ongoing development aims to enhance memory management in AI agents, ensuring they can provide more coherent and contextually relevant interactions. Types of Memory in AI Agents\\nSign up for Latest SuperAGI Updates\\n\"*\" indicates required fields\\nSuperAGI builds infrastructure components, tools, frameworks and models to enable opensource AGI\\ncommunity@superagi.com\\nFor Developers\\nDocs\\nGitHub\\nReleases\\nRoadmap\\nAPIs\\nCommunity\\nSupport Forum\\nMarketplace\\nSocial Mentions\\nReddit\\nCollectibles\\nResources\\nBlog\\nUse Cases\\nAGI Research Lab\\nTutorials\\nImportant Links\\nSuperAGI Cloud\\nApp Spotlight\\nSuperCoder\\nArchitecture\\n Check it out✨\\nFeatures\\nAction Console\\nResource Manager\\nTrajectory Fine-Tuning\\n\\u200c\\nMultiple Vector DBs\\nMulti-LLM Support\\nAgent Workflows\\nMarketplace\\nAgent Templates\\nDiscord\\nGitHub\\nTwitter\\nReddit\\nYoutube\\nTowards AGI (part 1): Agents with Memory\\nFebruary 6, 2024\\n7 mins read\\nAgents are an emerging class of artificial intelligence (AI) systems that use large language models (LLMs) to interact with the world. In a professional setup like this, the agent is responsible for extracting tasks from conversations and passing them to an employee and once the employee completes the task the agent will convey the output to the user. Then use the solutions of those basic tasks as in-context examples to solve the current task.\\nConclusion & Next Steps\\nIn this blog, we saw that design choices for Memory depend on the end use case. This analogy is better captured in the following table:\\nDeep dive into various types of Agent Memory\\nChoosing the right Memory design in Production\\nSince agents are powered by LLMs, they are inherently probabilistic.\\nMemory: an AI agent combines the ability to use short-term memory to process chat-based prompts and follow-up prompts with longer-term data retention and recall (often via retrieval augmented generation, or RAG). Tool use: an agent can query APIs to request additional information or execute an action based on an end user\\'s request.')]}\n"
     ]
    }
   ],
   "source": [
    "graph_input = {\"question\": \"What are the types of agent memory?\", \"max_retries\": 3}\n",
    "for event in graph.stream(graph_input, stream_mode=\"values\"):\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "086062b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---ROUTE QUESTION---\n",
      "---ROUTE QUESTION TO WEB SEARCH---\n",
      "{'question': 'What is the recent Mistral multi-modal model?', 'max_retries': 3, 'loop_step': 0}\n",
      "---WEB SEARCH---\n",
      "{'question': 'What is the recent Mistral multi-modal model?', 'max_retries': 3, 'loop_step': 0, 'documents': [Document(metadata={}, page_content='Mistral releases Pixtral 12B, its first multimodal model French AI startup Mistral has released its first model that can process images as well as text. Built on one of Mistral’s text models, Nemo 12B, the new model can answer questions about an arbitrary number of images of an arbitrary size given either URLs or images encoded using base64, the binary-to-text encoding scheme. Similar to other multimodal models such as Anthropic’s Claude family and OpenAI’s GPT-4o, Pixtral 12B should — at least in theory — be able to perform tasks like captioning images and counting the number of objects in a photo. Available via a torrent link on GitHub and AI and machine learning development platform Hugging Face, Pixtral 12B can be downloaded, fine-tuned and used under an Apache 2.0 license without restrictions.\\nThis week, it\\'s Mistral\\'s turn with their new multi-modal model: Pixtral 12B. Pixtral 12B from Mistral AI A multi-modal AI can look at both the picture and the word “cat” to fully understand that it’s seeing a cat. Pixtral 12B is a new AI multimodal model created by Mistral AI. Pixtral 12B works by “looking” at images and “reading” text at the same time. For example, if you upload a picture of a city skyline and ask, “Which city is this?” Pixtral 12B uses both the image (the buildings, landmarks) and the text (your question) to figure it out. Pixtral 12B combines both, making it more versatile and efficient than those older models. Pixtral 12B is available on Hugging Face, a platform known for AI and machine learning development.\\nMistral releases ‘Pixtral 12B,’ its first multimodal AI model It\\'s not clear what image data the French AI startup firm used to develop the Pixtral 12B. French AI startup Mistral has released its first multimodal model, the Pixtral 12B, which can handle both text and images, according to\\xa0Techcrunch. The model uses 12 billion parameters and is based on Mistral’s Nemo 12B text model. Pixtral 12B can answer questions about images via URLs or images encoded with base64 such as how many copies of a certain object are visible. Most generative AI (genAI) models have been partially trained on copyrighted material, which has led to lawsuits from copyright owners. It is unclear what image data Mistral used to develop the Pixtral 12B.\\nPixtral 12B is here: Mistral’s new multimodal AI can analyze images without any limits Today, the French AI startup taking on the likes of OpenAI and Anthropic released Pixtral 12B, its first ever multimodal model with both language and vision processing capabilities baked in. While the official details of the new model, including the data it was trained upon, remain under wraps, the core idea appears that Pixtral 12B will allow users to analyze images while combining text prompts with them. Since its launch last year, Mistral has not only built a strong pipeline of models taking on leading AI labs like OpenAI but also partnered with industry giants such as Microsoft, AWS and Snowflake to expand the reach of its technology.\\nFrench startup Mistral unveils Pixtral 12B multimodal AI model | Mashable Tech Science Life Social Good Entertainment Deals Shopping Games French startup Mistral unveils Pixtral 12B, its first multimodal AI model French AI startup Mistral has dropped its first multimodal model, Pixtral 12B, capable of processing both images and text. As noted by Tech Crunch, Mistral, like many AI firms, likely trained Pixtral 12B using vast quantities of publicly available web data — a practice that’s sparked lawsuits from copyright holders challenging the \"fair use\" argument often made by tech companies. Currently residing in Chicago, Illinois, Chance Townsend is an Assistant Editor at Mashable covering tech, entertainment, dating apps, and whatever else comes his way.')]}\n",
      "---GENERATE---\n",
      "---CHECK HALLUCINATIONS---\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION vs QUESTION---\n",
      "---DECISION: GENERATION ADDRESSES QUESTION---\n",
      "{'question': 'What is the recent Mistral multi-modal model?', 'generation': AIMessage(content=\"Mistral's recent multi-modal model is Pixtral 12B, which can process both images and text. It is built on Mistral's Nemo 12B text model and can answer questions about images via URLs or images encoded with base64. Pixtral 12B can perform tasks like captioning images and counting objects in a photo.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 74, 'prompt_tokens': 969, 'total_tokens': 1043, 'completion_time': 0.296, 'prompt_time': 0.18504115, 'queue_time': 0.003563297000000021, 'total_time': 0.48104115}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_5c5d1b5cfb', 'finish_reason': 'stop', 'logprobs': None}, id='run-045f3a45-f728-40ac-9a57-a63c8c8766d7-0', usage_metadata={'input_tokens': 969, 'output_tokens': 74, 'total_tokens': 1043}), 'max_retries': 3, 'loop_step': 1, 'documents': [Document(metadata={}, page_content='Mistral releases Pixtral 12B, its first multimodal model French AI startup Mistral has released its first model that can process images as well as text. Built on one of Mistral’s text models, Nemo 12B, the new model can answer questions about an arbitrary number of images of an arbitrary size given either URLs or images encoded using base64, the binary-to-text encoding scheme. Similar to other multimodal models such as Anthropic’s Claude family and OpenAI’s GPT-4o, Pixtral 12B should — at least in theory — be able to perform tasks like captioning images and counting the number of objects in a photo. Available via a torrent link on GitHub and AI and machine learning development platform Hugging Face, Pixtral 12B can be downloaded, fine-tuned and used under an Apache 2.0 license without restrictions.\\nThis week, it\\'s Mistral\\'s turn with their new multi-modal model: Pixtral 12B. Pixtral 12B from Mistral AI A multi-modal AI can look at both the picture and the word “cat” to fully understand that it’s seeing a cat. Pixtral 12B is a new AI multimodal model created by Mistral AI. Pixtral 12B works by “looking” at images and “reading” text at the same time. For example, if you upload a picture of a city skyline and ask, “Which city is this?” Pixtral 12B uses both the image (the buildings, landmarks) and the text (your question) to figure it out. Pixtral 12B combines both, making it more versatile and efficient than those older models. Pixtral 12B is available on Hugging Face, a platform known for AI and machine learning development.\\nMistral releases ‘Pixtral 12B,’ its first multimodal AI model It\\'s not clear what image data the French AI startup firm used to develop the Pixtral 12B. French AI startup Mistral has released its first multimodal model, the Pixtral 12B, which can handle both text and images, according to\\xa0Techcrunch. The model uses 12 billion parameters and is based on Mistral’s Nemo 12B text model. Pixtral 12B can answer questions about images via URLs or images encoded with base64 such as how many copies of a certain object are visible. Most generative AI (genAI) models have been partially trained on copyrighted material, which has led to lawsuits from copyright owners. It is unclear what image data Mistral used to develop the Pixtral 12B.\\nPixtral 12B is here: Mistral’s new multimodal AI can analyze images without any limits Today, the French AI startup taking on the likes of OpenAI and Anthropic released Pixtral 12B, its first ever multimodal model with both language and vision processing capabilities baked in. While the official details of the new model, including the data it was trained upon, remain under wraps, the core idea appears that Pixtral 12B will allow users to analyze images while combining text prompts with them. Since its launch last year, Mistral has not only built a strong pipeline of models taking on leading AI labs like OpenAI but also partnered with industry giants such as Microsoft, AWS and Snowflake to expand the reach of its technology.\\nFrench startup Mistral unveils Pixtral 12B multimodal AI model | Mashable Tech Science Life Social Good Entertainment Deals Shopping Games French startup Mistral unveils Pixtral 12B, its first multimodal AI model French AI startup Mistral has dropped its first multimodal model, Pixtral 12B, capable of processing both images and text. As noted by Tech Crunch, Mistral, like many AI firms, likely trained Pixtral 12B using vast quantities of publicly available web data — a practice that’s sparked lawsuits from copyright holders challenging the \"fair use\" argument often made by tech companies. Currently residing in Chicago, Illinois, Chance Townsend is an Assistant Editor at Mashable covering tech, entertainment, dating apps, and whatever else comes his way.')]}\n"
     ]
    }
   ],
   "source": [
    "graph_input = {\"question\": \"What is the recent Mistral multi-modal model?\", \"max_retries\": 3}\n",
    "for event in graph.stream(graph_input, stream_mode=\"values\"):\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f759b38d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Mistral's recent multi-modal model is Pixtral 12B, which can process both images and text. It is built on Mistral's Nemo 12B text model and can answer questions about images via URLs or images encoded with base64. Pixtral 12B can perform tasks like captioning images and counting objects in a photo.\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event['generation'].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fe3d07b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---ROUTE QUESTION---\n",
      "---ROUTE QUESTION TO WEB SEARCH---\n",
      "{'question': 'who won the last football world cup ?', 'loop_step': 0}\n",
      "---WEB SEARCH---\n",
      "{'question': 'who won the last football world cup ?', 'loop_step': 0, 'documents': [Document(metadata={}, page_content='Mbappé, on the other hand, was anonymous until bursting into life by scoring two goals in a 97-second span — one an 80th-minute penalty, the other a volley from just inside the area after a quick exchange of passes — to take the game to extra time at 2-2.\\nMessi still had plenty of energy and he was on hand to tap in his second goal in the 108th minute, with a France defender clearing the ball just after it had crossed the line. Messi wins World Cup, Argentina beats France on penalties\\nArgentina’s Lionel Messi lifts the trophy after winning the World Cup final soccer match between Argentina and France at the Lusail Stadium in Lusail, Qatar, Sunday, Dec. 18, 2022. France’s Kylian Mbappe runs past Argentina’s Lionel Messi as he retrieves the ball after scoring his side’s first goal during the World Cup final soccer match between Argentina and France at the Lusail Stadium in Lusail, Qatar, Sunday, Dec. 18, 2022. France’s Kylian Mbappe runs past Argentina’s Lionel Messi as he retrieves the ball after scoring his side’s first goal during the World Cup final soccer match between Argentina and France at the Lusail Stadium in Lusail, Qatar, Sunday, Dec. 18, 2022. France’s Kylian Mbappe runs past Argentina’s Lionel Messi as he retrieves the ball after scoring his side’s first goal during the World Cup final soccer match between Argentina and France at the Lusail Stadium in Lusail, Qatar, Sunday, Dec. 18, 2022.\\nFIFA World Cup winners list\\nRelated content\\nArgentina in FIFA World Cups: Of Diego Maradona’s feat of gold and Leo Messi’s redemption\\nMost FIFA World Cup wins: Brazil lead men’s winners list; USA dominate women’s roll of honour\\nYou may like Didier Deschamps was the manager of the French team that won the 2018 FIFA World Cup, making him the third individual to win the title both as a player and a manager. FIFA World Cup winners: Why Brazilians are unique and Germany, Italy relentless - full roll of honour\\nBrazil have won the FIFA World Cup five times, the most in history, while Germany and Italy have won it four times each. The FIFA World Cup got a new winner next in 1998 as modern football giants France, under the captaincy of Didier Deschamps, beat Brazil in the final to win their first title on home soil.\\n England’s Geoff Hurst scored three goals in the 4-2 win over West Germany and was the first man to score a hat-trick in a FIFA World Cup final.\\n\\nT.E.S. Latest\\nCurrent\\nPopular Pages\\nLatest Sports Added\\n→ How to Cite\\nPAGES\\nhome\\nsearch\\nsitemap\\nstore\\nSOCIAL MEDIA\\nnewsletter\\nfacebook\\ntwitter\\nSECURITY\\nprivacy policy\\ndisclaimer\\ncopyright\\nABOUT\\ncontact\\nauthor info\\nadvertising\\n©1997-2023 Topend Sports Network 1 Brazil 5 Times Winner / 6 Times in the Final\\n2 Germany 4 Times Winner/ 8 Times in the Final\\n3 Italy 4 Times Winner/ 6 Times in the Final\\n4 Argentina 2 Times Winner/ 5 Times in the Final\\n5 Uruguay 2 Times Winner / 2 Times in the Final\\n6 France 1 Time Winner / 2 Times in the Final\\n Time Winner / 2 Time in the Final\\n10 Sweden 0 Time Winner / 1 Time in the Final\\nSearch This Site\\nFIFA World Cup Extra\\nThe current men\\'s World Cup is being held in Qatar 2022, the next women\\'s world cup will be in Australia/New Zealand 2023. Or the winners of the Women\\'s World Cup?\\nRelated Pages\\nComments\\nCommentling on this page is generally closed, though I will post some selected comments.\\n 7 Spain 1 Time Winner / 1 Time in the Final\\n7 England 1 Time Winner/ 1 Time in the Final\\n8 Netherlands 0\\nHere are some of the other reflections from wowed spectators around the world:\\n\"On top of the world\": Argentina players struggle to find the words to sum up World Cup triumph\\nFrom CNN\\'s Ben Church\\nLionel Messi and his\\xa0Argentina\\xa0teammates were certainly made to suffer, but eventually they got their hands on the\\xa0World Cup trophy Sunday, in arguably the greatest final of tournament history.\\n Here\\'s where things stood when the final whistle blew:\\n8 goals\\n7 goals\\n4 goals\\nLionel Messi wins the Golden Ball award\\nAfter his team\\'s triumph in the World Cup final, Argentina legend Lionel Messi was awarded the Golden Ball, the prize given to the best player in the tournament.\\n Qatar’s government\\xa0says\\xa0that over\\xa030,000\\xa0foreign laborers\\xa0were brought in to build\\xa0the\\xa0stadiums\\xa0for the World Cup.\\xa0Seven\\xa0new stadiums for the World Cup rose from the desert, and the Gulf state expanded its airport, constructed new hotels, rail and highways.\\n Mbappé hat trick helps him edge out Messi for the Golden Boot\\nThe race for the Golden Boot — the award for the player who scores the most goals in the tournament — hung in the balance heading into Sunday\\'s clash between Argentina and France.\\n Here\\'s what you need to know about the 2026 World Cup\\nFrom CNN\\'s Matt Foster\\xa0and\\xa0Matias Grez\\nMatches for the 2026\\xa0World Cup\\xa0will be held in 11 US cities as well as three host sites in\\xa0Mexico\\xa0and two in\\xa0Canada, soccer’s world governing body, FIFA, announced.\\n\\nAfter the exciting conclusion of the 2022 World Cup, Brazil lead the way with five titles with Germany and Italy one behind on four and Argentina on three. The host country claimed the World Cup again four years later, with Italy winning the first of their four titles with an extra-time victory over Czechoslovakia. The World Cup returned in Brazil in 1950, and Uruguay pipped the hosts to the trophy in the only tournament that did not have a final. England’s success at that tournament made them the first host country to win the World Cup title since Italy in 1934. He scored a semi-final winner against hosts Germany before bagging the decisive penalty in the final against France to deliver Italy’s first World Cup title since 1982.')]}\n",
      "---GENERATE---\n",
      "---CHECK HALLUCINATIONS---\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION vs QUESTION---\n",
      "---DECISION: GENERATION ADDRESSES QUESTION---\n",
      "{'question': 'who won the last football world cup ?', 'generation': AIMessage(content='Argentina won the last football World Cup, defeating France in the final on penalties. The match was played on December 18, 2022, at the Lusail Stadium in Lusail, Qatar. Lionel Messi led Argentina to victory and was awarded the Golden Ball as the best player in the tournament.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 63, 'prompt_tokens': 1431, 'total_tokens': 1494, 'completion_time': 0.252, 'prompt_time': 0.260202774, 'queue_time': 0.00358065599999996, 'total_time': 0.512202774}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_b6828be2c9', 'finish_reason': 'stop', 'logprobs': None}, id='run-b3135df8-249d-4fe6-b6b2-a41dce4100e4-0', usage_metadata={'input_tokens': 1431, 'output_tokens': 63, 'total_tokens': 1494}), 'loop_step': 1, 'documents': [Document(metadata={}, page_content='Mbappé, on the other hand, was anonymous until bursting into life by scoring two goals in a 97-second span — one an 80th-minute penalty, the other a volley from just inside the area after a quick exchange of passes — to take the game to extra time at 2-2.\\nMessi still had plenty of energy and he was on hand to tap in his second goal in the 108th minute, with a France defender clearing the ball just after it had crossed the line. Messi wins World Cup, Argentina beats France on penalties\\nArgentina’s Lionel Messi lifts the trophy after winning the World Cup final soccer match between Argentina and France at the Lusail Stadium in Lusail, Qatar, Sunday, Dec. 18, 2022. France’s Kylian Mbappe runs past Argentina’s Lionel Messi as he retrieves the ball after scoring his side’s first goal during the World Cup final soccer match between Argentina and France at the Lusail Stadium in Lusail, Qatar, Sunday, Dec. 18, 2022. France’s Kylian Mbappe runs past Argentina’s Lionel Messi as he retrieves the ball after scoring his side’s first goal during the World Cup final soccer match between Argentina and France at the Lusail Stadium in Lusail, Qatar, Sunday, Dec. 18, 2022. France’s Kylian Mbappe runs past Argentina’s Lionel Messi as he retrieves the ball after scoring his side’s first goal during the World Cup final soccer match between Argentina and France at the Lusail Stadium in Lusail, Qatar, Sunday, Dec. 18, 2022.\\nFIFA World Cup winners list\\nRelated content\\nArgentina in FIFA World Cups: Of Diego Maradona’s feat of gold and Leo Messi’s redemption\\nMost FIFA World Cup wins: Brazil lead men’s winners list; USA dominate women’s roll of honour\\nYou may like Didier Deschamps was the manager of the French team that won the 2018 FIFA World Cup, making him the third individual to win the title both as a player and a manager. FIFA World Cup winners: Why Brazilians are unique and Germany, Italy relentless - full roll of honour\\nBrazil have won the FIFA World Cup five times, the most in history, while Germany and Italy have won it four times each. The FIFA World Cup got a new winner next in 1998 as modern football giants France, under the captaincy of Didier Deschamps, beat Brazil in the final to win their first title on home soil.\\n England’s Geoff Hurst scored three goals in the 4-2 win over West Germany and was the first man to score a hat-trick in a FIFA World Cup final.\\n\\nT.E.S. Latest\\nCurrent\\nPopular Pages\\nLatest Sports Added\\n→ How to Cite\\nPAGES\\nhome\\nsearch\\nsitemap\\nstore\\nSOCIAL MEDIA\\nnewsletter\\nfacebook\\ntwitter\\nSECURITY\\nprivacy policy\\ndisclaimer\\ncopyright\\nABOUT\\ncontact\\nauthor info\\nadvertising\\n©1997-2023 Topend Sports Network 1 Brazil 5 Times Winner / 6 Times in the Final\\n2 Germany 4 Times Winner/ 8 Times in the Final\\n3 Italy 4 Times Winner/ 6 Times in the Final\\n4 Argentina 2 Times Winner/ 5 Times in the Final\\n5 Uruguay 2 Times Winner / 2 Times in the Final\\n6 France 1 Time Winner / 2 Times in the Final\\n Time Winner / 2 Time in the Final\\n10 Sweden 0 Time Winner / 1 Time in the Final\\nSearch This Site\\nFIFA World Cup Extra\\nThe current men\\'s World Cup is being held in Qatar 2022, the next women\\'s world cup will be in Australia/New Zealand 2023. Or the winners of the Women\\'s World Cup?\\nRelated Pages\\nComments\\nCommentling on this page is generally closed, though I will post some selected comments.\\n 7 Spain 1 Time Winner / 1 Time in the Final\\n7 England 1 Time Winner/ 1 Time in the Final\\n8 Netherlands 0\\nHere are some of the other reflections from wowed spectators around the world:\\n\"On top of the world\": Argentina players struggle to find the words to sum up World Cup triumph\\nFrom CNN\\'s Ben Church\\nLionel Messi and his\\xa0Argentina\\xa0teammates were certainly made to suffer, but eventually they got their hands on the\\xa0World Cup trophy Sunday, in arguably the greatest final of tournament history.\\n Here\\'s where things stood when the final whistle blew:\\n8 goals\\n7 goals\\n4 goals\\nLionel Messi wins the Golden Ball award\\nAfter his team\\'s triumph in the World Cup final, Argentina legend Lionel Messi was awarded the Golden Ball, the prize given to the best player in the tournament.\\n Qatar’s government\\xa0says\\xa0that over\\xa030,000\\xa0foreign laborers\\xa0were brought in to build\\xa0the\\xa0stadiums\\xa0for the World Cup.\\xa0Seven\\xa0new stadiums for the World Cup rose from the desert, and the Gulf state expanded its airport, constructed new hotels, rail and highways.\\n Mbappé hat trick helps him edge out Messi for the Golden Boot\\nThe race for the Golden Boot — the award for the player who scores the most goals in the tournament — hung in the balance heading into Sunday\\'s clash between Argentina and France.\\n Here\\'s what you need to know about the 2026 World Cup\\nFrom CNN\\'s Matt Foster\\xa0and\\xa0Matias Grez\\nMatches for the 2026\\xa0World Cup\\xa0will be held in 11 US cities as well as three host sites in\\xa0Mexico\\xa0and two in\\xa0Canada, soccer’s world governing body, FIFA, announced.\\n\\nAfter the exciting conclusion of the 2022 World Cup, Brazil lead the way with five titles with Germany and Italy one behind on four and Argentina on three. The host country claimed the World Cup again four years later, with Italy winning the first of their four titles with an extra-time victory over Czechoslovakia. The World Cup returned in Brazil in 1950, and Uruguay pipped the hosts to the trophy in the only tournament that did not have a final. England’s success at that tournament made them the first host country to win the World Cup title since Italy in 1934. He scored a semi-final winner against hosts Germany before bagging the decisive penalty in the final against France to deliver Italy’s first World Cup title since 1982.')]}\n"
     ]
    }
   ],
   "source": [
    "graph_input = {\"question\": \"who won the last football world cup ?\"}\n",
    "for event in graph.stream(graph_input, stream_mode=\"values\"):\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "50ee737c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Argentina won the last football World Cup, defeating France in the final on penalties. The match was played on December 18, 2022, at the Lusail Stadium in Lusail, Qatar. Lionel Messi led Argentina to victory and was awarded the Golden Ball as the best player in the tournament.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event['generation'].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d590f122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---ROUTE QUESTION---\n",
      "---ROUTE QUESTION TO WEB SEARCH---\n",
      "---WEB SEARCH---\n",
      "---GENERATE---\n",
      "---CHECK HALLUCINATIONS---\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION vs QUESTION---\n",
      "---DECISION: GENERATION ADDRESSES QUESTION---\n"
     ]
    }
   ],
   "source": [
    "graph_input = {\"question\": \"who won the last football africa cup ?\"}\n",
    "final_event = None\n",
    "for event in graph.stream(graph_input, stream_mode=\"values\"):\n",
    "    final_event = event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a2394d5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Ivory Coast won the last Africa Cup of Nations, defeating Nigeria 2-1 in the final. This match was hosted in Abidjan in 2024.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_event['generation'].content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
